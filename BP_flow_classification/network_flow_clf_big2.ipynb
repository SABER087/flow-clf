{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "大的数据集 所有样本做训练集\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import datetime\n",
    "starttime = datetime.datetime.now()\n",
    "# read CSV file directly from a URL and save the results\n",
    "# NOT: First extract zip file\n",
    "#data = pd.read_csv('NISM.csv',   quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "data = pd.read_csv('ourdataset_test_small4.csv',   quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "\n",
    "#families whose count is greater than 30 \n",
    "#class_group = df.groupby(\"class\")\n",
    "\n",
    "print(data.groupby('label').size())\n",
    "\n",
    "# extact features and labels\n",
    "# X feature set, y labels\n",
    "X = data.loc[:,data.columns[:-1]] # -1 label kolonunu refer ediyor\n",
    "y = data.label\n",
    "X = X.values\n",
    "\n",
    "print(X.shape)\n",
    "# print X\n",
    "# print '----------------------------------------------'\n",
    "\n",
    "# Generally, this is one of the most commonly used preprocessing step.特征值预处理\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import preprocessing\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "#print(clf.feature_importances_)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_final=X_new\n",
    "X=X_new\n",
    "print(X.shape)\n",
    "# print X\n",
    "\n",
    "#数据归一化 和 标准化\n",
    "# normalize the data attributes  实验发现效果不理想 因此不做归一化\n",
    "# normalized_X = preprocessing.normalize(X)\n",
    "# standardize the data attributes 数据标准化 效果拔群\n",
    "standardized_X = preprocessing.scale(X)\n",
    "X = standardized_X\n",
    "\n",
    "from sklearn import linear_model, ensemble, svm, tree, neural_network, metrics, naive_bayes\n",
    "from sklearn import cross_validation\n",
    "\n",
    "#训练\n",
    "def train_flow_classification(X, y, clf_class, shuffle=True, n_folds=10, **kwargs):\n",
    "#     stratified_k_fold = cross_validation.StratifiedKFold(y, n_folds=n_folds, shuffle=shuffle)\n",
    "#     y_pred = y.copy()\n",
    "#     print stratified_k_fold\n",
    "    clf = clf_class(**kwargs)\n",
    "    clf.fit(X,y)\n",
    "#     for ii, jj in stratified_k_fold:\n",
    "#         X_train, X_test = X[ii], X[jj]\n",
    "#         y_train = y[ii]\n",
    "#         #这里的 clf应该放在 for循环的外面，不然 分类器每次for循环都重新训练了\n",
    "# #         clf = clf_class(**kwargs)\n",
    "#         clf.fit(X_train,y_train)\n",
    "    return clf\n",
    "\n",
    "#预测验证\n",
    "def pred_flow_classification(X, y, clf, shuffle=True, n_folds=10, **kwargs):\n",
    "    stratified_k_fold = cross_validation.StratifiedKFold(y, n_folds=n_folds, shuffle=shuffle)\n",
    "    y_pred = y.copy()\n",
    "    clf_train = clf\n",
    "    print stratified_k_fold\n",
    "#     print y_pred\n",
    "    for ii, jj in stratified_k_fold:\n",
    "        X_train, X_test = X[ii], X[jj]\n",
    "        y_train = y[ii]\n",
    "        y_pred[jj] = clf_train.predict(X_test)\n",
    "#         print 'y_pred    ',y_pred[jj]\n",
    "    return y_pred\n",
    "\n",
    "# cross validation of the ML algorithms\n",
    "def stratified_cv(X, y, clf_class, shuffle=True, n_folds=10, **kwargs):\n",
    "    stratified_k_fold = cross_validation.StratifiedKFold(y, n_folds=n_folds, shuffle=shuffle)\n",
    "    y_pred = y.copy()\n",
    "    print stratified_k_fold\n",
    "    #建议 clf = clf_class(**kwargs) 放在 for循环外面\n",
    "#     print y_pred\n",
    "    # ii+jj 的长度是样本总数，而 ii 表示用于训练的样本的序号集合，jj表示用于测试/预测的样本的序号集合\n",
    "    for ii, jj in stratified_k_fold:\n",
    "        X_train, X_test = X[ii], X[jj]\n",
    "        y_train = y[ii]\n",
    "        #这里的 clf应该放在 for循环的里面，每次for循环分类器都用于重新训练，因为用到了交叉验证，它划分了10份样本，每次拿其中一份做预测样本\n",
    "        #其余九份做训练，以此来对预测的那一份样本做预测和比较，经过10次for循环所有的10份样本都会被用来交叉验证，最终预测的样本总数等于原样本\n",
    "        #这样的好处是没有拿所有样本做训练集，而是每次只取其中九份做训练，留一份做预测，一是防止过拟合二是增加实验可信度\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[jj] = clf.predict(X_test)\n",
    "#         print 'y_pred    ',y_pred[jj]\n",
    "    return y_pred\n",
    "\n",
    "# print accuracies of the ML algo 其他机器学习算法的 分类准确率分数 比较，分类准确率分数是指所有分类正确的百分比\n",
    "# print('Random Forest Classifier:       {:.2f}'.format(metrics.accuracy_score(y, stratified_cv(X, y, ensemble.RandomForestClassifier))))\n",
    "# print('Support vector machine(SVM):   {:.2f}'.format(metrics.accuracy_score(y, stratified_cv(X, y, svm.SVC))))\n",
    "# print('Logistic Regression:            {:.2f}'.format(metrics.accuracy_score(y, stratified_cv(X, y, linear_model.LogisticRegression))))\n",
    "# print('Native Network:            {:.2f}'.format(metrics.accuracy_score(y, stratified_cv(X, y, neural_network.MLPClassifier, activation ='relu',\n",
    "#                                                                                         hidden_layer_sizes =(30,30,30,30,30,30,30,30,30)))))\n",
    "#所有样本做训练集\n",
    "clf_train = train_flow_classification(X, y, neural_network.MLPClassifier, activation ='relu',hidden_layer_sizes =(30,30,30,30,30,30,30,30,30))\n",
    "#预测得到的样本 y_pred\n",
    "y_pred = pred_flow_classification(X, y,clf_train)\n",
    "#分类准确率分数\n",
    "#交叉验证方式 做训练集 预测得到的样本y_pred\n",
    "# y_pred = stratified_cv(X, y, neural_network.MLPClassifier, activation ='relu',hidden_layer_sizes =(30,30,30,30,30,30,30,30,30))\n",
    "print('Native Network:            {:.2f}'.format(metrics.accuracy_score(y, y_pred)))\n",
    "\n",
    "#混淆(xiao)矩阵\n",
    "print '混淆矩阵为 = \\n',metrics.confusion_matrix(y, y_pred, labels = [\"b'DNS'\",\"b'FTP'\",\"b'HTTP'\",\"b'TELNET'\",\"b'lime'\",\"b'localForwarding'\",\n",
    "                                                                 \"b'remoteForwarding'\",\"b'scp'\",\"b'sftp'\",\"b'shell'\",\"b'x11'\"])\n",
    "#新数据预测\n",
    "# X_new = np.row_stack((X_final, X_final[1]))\n",
    "# standardized_X = preprocessing.scale(X_new)\n",
    "# X_pred = [standardized_X[-1], X[1]]\n",
    "# print X_pred\n",
    "# print 'predict X_pred as  ',clf_train.predict(X_pred) \n",
    "\n",
    "print 'finish'\n",
    "#long running\n",
    "endtime = datetime.datetime.now()\n",
    "print ('运行时间 = %.2f s' % (endtime - starttime).seconds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
